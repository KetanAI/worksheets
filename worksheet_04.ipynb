{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 04\n",
    "\n",
    "Name:  Ketan Suhaas Saichandran\\\n",
    "UID: U68176921\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Distance & Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance & Similarity\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "a) In the minkowski distance, describe what the parameters p and d are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter p identifies the kind of minkowski distance we are calculating. It is also referred as the order of the norm or just \"p-norm\". d is the number of dimensions of the feature space (d-Dimensional), or the coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In your own words describe the difference between the Euclidean distance and the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Euclidean distance, the order of the norm is 2, while in Manhattan distance the order of the norm is 1. \n",
    "While calculating the Euclidean distance, we calculate the square root of the sum of the squares of differences between the feature values. And for the Manhattan distance, we calculate the sum of the absolute differences between the feature values. The Euclidean distances takes into account the diagonal paths involved when trying to reach a point B from A, and the actual magnitude of displacement is calculated. It gives us the radius of the sphere (in 3-D, centered at point A) where the point B lies on. In Manhattan distance, we only know by how much the feature values have changed in total (moving along the grid at right angles), although it might help solving some different set of problems. It all boils down to the problem we are solving, the choice of the norm order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A = (0, 0) and B = (1, 1). When:\n",
    "\n",
    "- p = 1, d(A, B) = 2\n",
    "- p = 2, d(A, B) = $\\sqrt{2} = 1.41$\n",
    "- p = 3, d(A, B) = $2^{1/3} = 1.26$\n",
    "- p = 4, d(A, B) = $2^{1/4} = 1.19$\n",
    "\n",
    "c) Describe what you think distance would look like when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the value of p approaches infinity, the distance converges to Chebyshev distance. It is just the maximum of absolute differences between features of two vectors (x and y) which is max(|xi - yi|) where i is the index of the feature. In the above case, applying limits, we get:\n",
    "D([0, 0], [1, 1]) = [(1^p + 1^p)^(1/p)]\n",
    "As p approaches infinity, the terms 1^p and 1^p both become 1, and the distance becomes:\n",
    "D([0, 0], [1, 1]) = [(1 + 1)^(1/p)]\n",
    "Now, as p goes to infinity, (2)^(1/p) approaches 1.\n",
    "Hence, in the above case the value is asymptotic to 1 when p is very large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Is the minkowski distance still a distance function when p < 1? Expain why / why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minkowski distance will not remain a distance function for p values less than 1, because the triangular inequality (d(a,b) <= d(a,b) + d(b,c)) does not hold true.\n",
    "Let's prove it with an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(a,b)+d(b,c) =  8.0\n",
      "d(a,c) =  8.000000000000002\n"
     ]
    }
   ],
   "source": [
    "#For example a = (0,0), b = (1,1), c = (2,2), p = 0.5\n",
    "import numpy as np\n",
    "def minkowski(b,a,p):\n",
    "    return np.sum(((a-b)**p))**(1/p)\n",
    "a = np.array([0,0])\n",
    "b = np.array([1,1])\n",
    "c = np.array([2,2])\n",
    "print(\"d(a,b)+d(b,c) = \",minkowski(a,b,0.5)+minkowski(b,c,0.5))\n",
    "print(\"d(a,c) = \",minkowski(a,c,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of d(a,c) comes out to be higher than d(a,b)+d(b,c), which violates the triangular inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) when would you use cosine similarity over the euclidan distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cosine similarity when the direction of the feature vector matters more than its magnitude. We look for proportional vectors.\n",
    "If direction is not a valid consideration in a certain scenario, we could use the euclidean distance to measure the magnitude of distance between two data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) what does the jaccard distance account for that the manhattan distance doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard distance takes into account the size of the union set which differentiates cases where the Manhattan distances are same but the data points are different in both cases. And also, Jaccard distance lies in [0,1]. \n",
    "For example, \n",
    "- Case-1, A = {1,1,0} and B = {1,0,1}\n",
    "- Case-2, A = {1,0} and B={0,1}, \n",
    "both the cases have equal Manhattan distances d(A,B) = 2,\n",
    "but Jaccard distance takes into account the number of features (dimensions), which gives Jaccard distances 0.667 and 1 respectively, which has more useful information. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"hello my name is Alice\"  \n",
    "s2 = \"hello my name is Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the union of words from both sentences, we can represent each sentence as a vector. Each element of the vector represents the presence or absence of the word at that index.\n",
    "\n",
    "In this example, the union of words is (\"hello\", \"my\", \"name\", \"is\", \"Alice\", \"Bob\") so we can represent the above sentences as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1]\n",
    "#     hello my name is    Bob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'Bob', 'hello', 'name', 'Alice', 'is']\n",
      "[1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus = [s1, s2]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)\n",
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new sentence to our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"hi my name is Claude\"\n",
    "corpus.append(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the new union of words used to represent s1, s2, and s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'Bob', 'hello', 'name', 'Alice', 'is', 'hi', 'Claude']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in s3.split():\n",
    "    if x not in all_words:\n",
    "        all_words.append(x)\n",
    "all_words\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Represent s1, s2, and s3 as vectors as above, using this new set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "v2 = [1 if x in s2 else 0 for x in all_words]\n",
    "v3 = [1 if x in s3 else 0 for x in all_words]\n",
    "v1,v2,v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that computes the manhattan distance between two vectors. Which pair of vectors are the most similar under that distance function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 4\n"
     ]
    }
   ],
   "source": [
    "def manhattan(v1, v2):\n",
    "    return np.sum(abs(np.array(v1)-np.array(v2)))\n",
    "print(manhattan(v1,v2),manhattan(v2,v3),manhattan(v3,v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectors v1 and v2, or sentences s1 and s2 are similar under manhattan distance function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a matrix of all these vectors (row major) and add the following sentences in vector form:\n",
    "\n",
    "- \"hi Alice\"\n",
    "- \"hello Claude\"\n",
    "- \"Bob my name is Claude\"\n",
    "- \"hi Claude my name is Alice\"\n",
    "- \"hello Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"hi Alice\", \"hello Claude\", \"Bob my name is Claude\",\"hi Claude my name is Alice\",\"hello Bob\"]\n",
    "data = []\n",
    "for s in corpus:\n",
    "    v = [1 if w in s else 0 for w in all_words]\n",
    "    data.append(v)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How many rows and columns does this matrix have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 5 rows and 8 columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) When using the Manhattan distance, which two sentences are the most similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 7., 4., 4.],\n",
       "       [4., 0., 5., 6., 2.],\n",
       "       [7., 5., 0., 3., 5.],\n",
       "       [4., 6., 3., 0., 8.],\n",
       "       [4., 2., 5., 8., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_distances = np.zeros((5,5))\n",
    "for i in range(0,5):\n",
    "    for j in range(0,5):\n",
    "        m_distances[i,j] = manhattan(data[i],data[j])\n",
    "m_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting distances between every pair, we get that sentences \"hello Claude\" and \"hello Bob\" are the most similar when using Manhattan distance (2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
