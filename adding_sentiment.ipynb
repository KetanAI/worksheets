{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "testingSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\91960\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def map_sentiment_to_score(sentiment_scores):\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    predicted_score = (compound_score + 1) * 2.5  # Scale to a 0-5 score range\n",
    "    return predicted_score\n",
    "\n",
    "def predict_review_score(review_text):\n",
    "    sentiment_scores = analyzer.polarity_scores(review_text)\n",
    "    predicted_score = map_sentiment_to_score(sentiment_scores)\n",
    "    return predicted_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process(df):\n",
    "\n",
    "    df['Helpfulness'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "    df['Helpfulness'] = df['Helpfulness'].fillna(0)\n",
    "\n",
    "    df['ReviewLength'] = df.apply(lambda row : len(row['Text'].split()) if type(row['Text']) == str else 0, axis = 1)\n",
    "    \n",
    "    df['CombinedText'] = df['Summary'] + ' ' + df['Text']\n",
    "\n",
    "    df['CombinedText'] = df['CombinedText'].str.lower()\n",
    "    df['CombinedText'] = df['CombinedText'].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "    #df['CombinedText'].apply(lambda x : predict_review_score(x) if type(x)==str else 2.5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "train_processed = process(trainingSet)\n",
    "\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "testX= pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "\n",
    "testX = testX.drop(columns=['Score_x'])\n",
    "testX = testX.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "trainX =  train_processed[train_processed['Score'].notnull()]\n",
    "\n",
    "testX = testX.drop(columns=['Text','Summary','ProductId','UserId','Time'])\n",
    "trainX = trainX.drop(columns=['Text','Summary','ProductId','UserId','Time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testX.to_csv(\"./data/X_test.csv\", index=False)\n",
    "trainX.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = pd.read_csv(\"./data/X_train.csv\")\n",
    "X_submission = pd.read_csv(\"./data/X_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['sentiment'] = X_train['CombinedText'].apply(lambda x : predict_review_score(x) if type(x)==str else 2.5)\n",
    "X_submission['sentiment'] = X_submission['CombinedText'].apply(lambda x : predict_review_score(x) if type(x)==str else 2.5)\n",
    "X_train.to_csv('sentiment_train.csv')\n",
    "X_submission.to_csv('sentiment_test.csv')"
   ]
  },
  
